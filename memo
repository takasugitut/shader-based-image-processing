<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0" />
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;

      margin: 0;
      overflow: hidden;
      background-color: #aaaaaa;
      background-attachment: fixed !important;
    }
  </style>
  <style>
    body {
      font-family: Monospace;
      margin: 0px;
      overflow: hidden;
    }
  </style>
</head>

<body>
  <script id="vertShader" type="shader">
      uniform mat4 modelViewMatrix;
      uniform mat4 projectionMatrix;

      precision highp float;

      in vec3 position;

      void main() {
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
      }
    </script>

  <script id="fragShader" type="shader">
      precision highp float;

      uniform sampler2D image;
      uniform float imageWidth;
      uniform int anaglyphsMethods;
      vec3 anaglyphsImg;

      uniform float colorScaleR;
      uniform float colorScaleG;
      uniform float colorScaleB;
      uniform bool invert;

      // Gaussian Filter
      uniform int gaussianFilter;
      uniform int kernelSize;
      uniform float sigma;

      // Laplacian Filter
      uniform int laplacianFilter;
      float laplacianKernel[9] = float[](
        0.0, -1.0, 0.0,
        -1.0, 4.0, -1.0,
        0.0, -1.0, 0.0
      );

      // Output Fragment Color
      out vec4 out_FragColor;

      void main(void) {
        vec4 leftImageTexture;
        vec4 rightImageTexture;
        
        vec2 texCoordLeft = vec2(gl_FragCoord.x / 2.0, gl_FragCoord.y) / vec2(imageWidth, textureSize(image, 0).y);
        vec2 texCoordRight = vec2(imageWidth / 2.0 + gl_FragCoord.x / 2.0, gl_FragCoord.y) / vec2(imageWidth, textureSize(image, 0).y);
        
        float laplacianTotal;
        
        if (gaussianFilter == 1) {
          float gaussianTotal;
          float pi = 3.1415926535897932384626433832795;
          float lp = 1.0 / (2.0 * pi * sigma * sigma);
          float rp = 1.0 / (2.0 * sigma * sigma);
          int halfKernelSize = kernelSize / 2;

          for (int i = -halfKernelSize; i <= halfKernelSize; i++) {
            for (int j = -halfKernelSize; j <= halfKernelSize; j++) {
              vec2 offset = vec2(float(i), float(j));
              float gaussianVal = lp * exp(-dot(offset, offset) * rp);
              gaussianTotal += gaussianVal;

              leftImageTexture += texture(image, texCoordLeft + offset / vec2(imageWidth, textureSize(image, 0).y)) * gaussianVal;
              rightImageTexture += texture(image, texCoordRight + offset / vec2(imageWidth, textureSize(image, 0).y)) * gaussianVal;
            }
          }
          
          leftImageTexture = leftImageTexture / gaussianTotal;
          rightImageTexture = rightImageTexture / gaussianTotal;
        } 
        
        if (laplacianFilter == 1) {
          float laplacianTotal;
          vec3 laplacianLeft = vec3(0.0);
          vec3 laplacianRight = vec3(0.0);

          for (int i = -1; i <= 1; i++) {
            for (int j = -1; j <= 1; j++) {
              vec2 offset = vec2(float(i), float(j));
              //float laplacianVal = laplacianKernel[(i + 1) * 3 + (j + 1)];
              //laplacianTotal += laplacianVal;

              //leftImageTexture += texture(image, texCoordLeft + offset / vec2(imageWidth, textureSize(image, 0).y)) * laplacianVal;
              //rightImageTexture += texture(image, texCoordRight + offset / vec2(imageWidth, textureSize(image, 0).y)) * laplacianVal;
              
              float laplacianVal;
              if (i == 0 && j == 0) {
                laplacianVal = 4.0;
              } else if (i == 0 || j == 0) {
                laplacianVal = -1.0;
              } else {
                laplacianVal = 0.0;
              }

              leftImageTexture += texture(image, texCoordLeft + offset / vec2(imageWidth, textureSize(image, 0).y)) * laplacianVal;
              rightImageTexture += texture(image, texCoordRight + offset / vec2(imageWidth, textureSize(image, 0).y)) * laplacianVal;
            }
          }
        }

        if (gaussianFilter == 0 && laplacianFilter == 0) {
          leftImageTexture = texelFetch(image, ivec2(int(gl_FragCoord.x / 2.), int(gl_FragCoord.y)), 0);
          rightImageTexture = texelFetch(image, ivec2(int(imageWidth / 2. + gl_FragCoord.x / 2.), int(gl_FragCoord.y)), 0);
        }

        vec3 rgb1 = vec3(leftImageTexture.r, leftImageTexture.g, leftImageTexture.b);
        vec3 rgb2 = vec3(rightImageTexture.r, rightImageTexture.g, rightImageTexture.b);

        vec3 trueAnaglyphs = vec3(
          0.299 * rgb1.r + 0.578 * rgb1.g + 0.114 * rgb1.b,
          0,
          0.299 * rgb2.r + 0.578 * rgb2.g + 0.114 * rgb2.b
        );

        vec3 grayAnaglyphs = vec3(
          0.299 * rgb1.r + 0.578 * rgb1.g + 0.114 * rgb1.b,
          0.299 * rgb2.r + 0.578 * rgb2.g + 0.114 * rgb2.b,
          0.299 * rgb2.r + 0.578 * rgb2.g + 0.114 * rgb2.b
        );

        vec3 colorAnaglyphs = vec3(
          rgb1.r,
          rgb2.g,
          rgb2.b
        );

        vec3 halfColorAnaglyphs = vec3(
          0.299 * rgb1.r + 0.578 * rgb1.g + 0.114 * rgb1.b,
          rgb2.g,
          rgb2.b
        );

        vec3 optimizedAnaglyphs = vec3(
          0.7 * rgb1.g + 0.3 * rgb1.b,
          rgb2.g,
          rgb2.b
        );

        switch(anaglyphsMethods) {
          case 1:
            anaglyphsImg = trueAnaglyphs;
            break;
          case 2:
            anaglyphsImg = grayAnaglyphs;
            break;
          case 3:
            anaglyphsImg = colorAnaglyphs;
            break;
          case 4:
            anaglyphsImg = halfColorAnaglyphs;
            break;
          case 5:
            anaglyphsImg = optimizedAnaglyphs;
            break;
          default:
            anaglyphsImg = rgb1;
            break;
        }

        out_FragColor = vec4(vec3(colorScaleR, colorScaleG, colorScaleB), 1.0) * vec4(anaglyphsImg, 1.0);

        if (invert)
        {
          out_FragColor = vec4(1, 1, 1, 0) - out_FragColor;
          out_FragColor.a = 1.0;
        }
      }
    </script>

  <script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>
  <script type="importmap">
		  {
			"imports": {
			  "three": "https://unpkg.com/three@0.161.0/build/three.module.js",
			  "three/addons/": "https://unpkg.com/three@0.161.0/examples/jsm/"
			}
		  }
		</script>

  <script type="module">
    import * as THREE from 'three';
    import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
    import { GUI } from "three/addons/libs/lil-gui.module.min.js";
    import WEBGL from "three/addons/capabilities/WebGL.js";

    function IVimageProcessing(height, width, imageProcessingMaterial) {
      this.height = height;
      this.width = width;

      //3 rtt setup
      this.scene = new THREE.Scene();
      this.orthoCamera = new THREE.OrthographicCamera(
        -1,
        1,
        1,
        -1,
        1 / Math.pow(2, 53),
        1
      );

      //4 create a target texture
      var options = {
        minFilter: THREE.NearestFilter,
        magFilter: THREE.NearestFilter,
        format: THREE.RGBAFormat,
        type: THREE.UnsignedByteType,
        //          type:THREE.FloatType,
        canvas: canvas,
        context: context,
      };
      this.rtt = new THREE.WebGLRenderTarget(width, height, options);

      var geom = new THREE.BufferGeometry();
      geom.setAttribute(
        "position",
        new THREE.BufferAttribute(
          new Float32Array([
            -1, -1, 0,
            1, -1, 0,
            1, 1, 0,
            -1, -1, 0,
            1, 1, 0,
            -1, 1, 0,
          ]),
          3
        )
      );
      this.scene.add(new THREE.Mesh(geom, imageProcessingMaterial));
    }

    function IVprocess(imageProcessing, renderer) {
      renderer.setRenderTarget(imageProcessing.rtt);
      renderer.render(imageProcessing.scene, imageProcessing.orthoCamera);
      renderer.setRenderTarget(null);
    }

    var camera, controls, scene, renderer, container;
    var context, canvas;
    var plan;

    var anaglyphMethodsObj = {
      anaglyph: 'None'
    };
    var anaglyphMethods = ["None", "True Anaglyphs", "Gray Anaglyphs", "Color Anaglyphs", "Half Color Anaglyphs", "Optimized Anaglyphs"]

    // VIDEO AND THE ASSOCIATED TEXTURE
    var video, videoTexture;
    var imageProcessing, imageProcessingMaterial;

    // GUI
    var gui;

    init();
    animate();

    function init() {
      if (WEBGL.isWebGL2Available() === false) {
        document.body.appendChild(WEBGL.getWebGL2ErrorMessage());
      }
      container = document.createElement("div");
      document.body.appendChild(container);

      canvas = document.createElement("canvas");
      context = canvas.getContext("webgl2");
      document.body.appendChild(canvas);

      scene = new THREE.Scene();

      renderer = new THREE.WebGLRenderer({
        canvas: canvas,
        context: context,
      });
      renderer.autoClear = false;
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.shadowMap.enabled = false;

      container.appendChild(renderer.domElement);

      camera = new THREE.PerspectiveCamera(
        75,
        window.innerWidth / window.innerHeight,
        0.001,
        10
      );
      camera.position.z = 0.5;
      controls = new OrbitControls(camera, renderer.domElement);
      controls.minDistance = 0.005;
      controls.maxDistance = 1.0;
      // controls.enableRotate = true;
      // controls.enablePan = true;
      controls.addEventListener("change", render);
      controls.update();

      video = document.createElement("video");
      video.src = "video.mp4";
      video.load();
      video.muted = true;
      video.loop = true;

      video.onloadeddata = function () {
        videoTexture = new THREE.VideoTexture(video);
        videoTexture.minFilter = THREE.NearestFilter;
        videoTexture.magFilter = THREE.NearestFilter;
        videoTexture.generateMipmaps = false;
        videoTexture.format = THREE.RGBAFormat;

        imageProcessingMaterial = new THREE.RawShaderMaterial({
          uniforms: {
            sizeDiv2: { type: "i", value: 1. },
            colorScaleR: { type: "f", value: 1.0 },
            colorScaleG: { type: "f", value: 1.0 },
            colorScaleB: { type: "f", value: 1.0 },
            invert: { type: "b", value: false },
            image: { type: "t", value: videoTexture },
            imageWidth: { type: "f", value: video.videoWidth },
            anaglyphsMethods: { type: "i", value: anaglyphMethods.indexOf(anaglyphMethodsObj.anaglyph) },
            gaussianFilter: { type: "i", value: 0 },
            laplacianFilter: { type: "i", value: 0 },
            kernelSize: { type: "i", value: 3 },
            sigma: { type: "f", value: .6 },
          },
          vertexShader: document.getElementById("vertShader").text,
          fragmentShader: document.getElementById("fragShader").text,
          glslVersion: THREE.GLSL3,
        });

        imageProcessing = new IVimageProcessing(
          video.videoHeight,
          video.videoWidth,
          imageProcessingMaterial
        );

        console.log(imageProcessing.width);

        var geometry = new THREE.PlaneGeometry(
          1,
          video.videoHeight / video.videoWidth
        );
        var material = new THREE.MeshBasicMaterial({
          map: imageProcessing.rtt.texture,
          side: THREE.DoubleSide,
        });

        plan = new THREE.Mesh(geometry, material);
        plan.receiveShadow = false;
        plan.castShadow = false;
        scene.add(plan);

        var geometry = new THREE.PlaneGeometry(
          1,
          video.videoHeight / video.videoWidth
        );
        var material = new THREE.MeshBasicMaterial({
          map: videoTexture,
          side: THREE.DoubleSide,
        });
        plan = new THREE.Mesh(geometry, material);
        plan.position.z = -0.5;
        plan.receiveShadow = false;
        plan.castShadow = false;
        scene.add(plan);

        var pausePlayObj = {
          pausePlay: function () {
            if (!video.paused) {
              console.log("pause");
              video.pause();
            } else {
              console.log("play");
              video.play();
            }
          },
          add10sec: function () {
            video.currentTime = video.currentTime + 10;
            console.log(video.currentTime);
          },
        };

        gui = new GUI();
        gui
          .add(imageProcessingMaterial.uniforms.colorScaleR, "value", 0, 1)
          .name("Red");
        gui
          .add(imageProcessingMaterial.uniforms.colorScaleG, "value", 0, 1)
          .name("Green");
        gui
          .add(imageProcessingMaterial.uniforms.colorScaleB, "value", 0, 1)
          .name("Blue");
        gui
          .add(imageProcessingMaterial.uniforms.invert, "value")
          .name("Invert");
        gui
          .add(anaglyphMethodsObj, 'anaglyph', anaglyphMethods)
          .name("Anaglyphs")
          .onChange(value => {
            imageProcessingMaterial.uniforms.anaglyphsMethods.value = anaglyphMethods.indexOf(value);
          });

        const gaussianFilterFolder = gui.addFolder("Gaussian Filter");
        const gaussianFilterObj = {
          gaussianFilter: false,
          laplacianFilter: false,
          kernelSize: 3,
          sigma: 0.6,
        }
        gaussianFilterFolder
          .add(gaussianFilterObj, "gaussianFilter")
          .name("Enabled")
          .onChange(value => {
            imageProcessingMaterial.uniforms.gaussianFilter.value = value ? 1 : 0;
          });
        gaussianFilterFolder
          .add(gaussianFilterObj, "laplacianFilter")
          .name("Laplacian Filter")
          .onChange(value => {
            imageProcessingMaterial.uniforms.laplacianFilter.value = value ? 1 : 0;
          });
        gaussianFilterFolder
          .add(imageProcessingMaterial.uniforms.kernelSize, "value", 3, 21, 2)
          .name("Kernel Size")
          .onChange(value => {
            if (value % 2 === 0) {
              imageProcessingMaterial.uniforms.kernelSize.value = value - 1;
            } else {
              imageProcessingMaterial.uniforms.kernelSize.value = value;
            }
          });
        gaussianFilterFolder
          .add(gaussianFilterObj, "sigma", 0.1, 10)
          .name("Sigma")
          .onChange(value => {
            imageProcessingMaterial.uniforms.sigma.value = value;
          });
        gui.add(pausePlayObj, "pausePlay").name("Pause/play video");
        gui.add(pausePlayObj, "add10sec").name("Add 10 seconds");

        video.play();
      };

      window.addEventListener("resize", onWindowResize, false);
    }

    function render() {
      renderer.clear();
      if (typeof imageProcessing !== "undefined") {
        IVprocess(imageProcessing, renderer);
      }
      renderer.render(scene, camera);
    }

    function animate() {
      requestAnimationFrame(animate);
      controls.update();
      render();
    }

    function onWindowResize() {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
      render();
    }
  </script>
</body>

</html>